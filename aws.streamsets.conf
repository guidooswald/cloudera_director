
#
# Copyright (c) 2014 Cloudera, Inc. All rights reserved.
#

#
# Simple AWS Cloudera Director configuration file with automatic role assignments
# that works as expected if you use a single instance type for all cluster nodes
#

#
# Cluster name
#

name: C5-SDC

#
# Cloud provider configuration (credentials, region or zone and optional default image)
#

provider {
    type: aws

    # Leave the accessKeyId and secretAccessKey fields blank when running on an instance
    # launched with an IAM role.

    # accessKeyId: ${?AWS_ACCESS_KEY_ID}
    # secretAccessKey: ${?AWS_SECRET_ACCESS_KEY}

    region: REPLACE-ME
    subnetId: subnet-REPLACE-ME
    securityGroupsIds: sg-REPLACE-ME

    instanceNamePrefix: prefix-REPLACE-ME

}

#
# SSH credentials to use to connect to the instances
#

ssh {
  #username: ec2-user # for RHEL image
  username: centos # for CentOS image
  privateKey: /REPLACE-ME.pem # with an absolute path to .pem file
}


#
# These instance properties will be applied to all instances.
#
common-instance-properties {
    #
    # Amazon Machine Image (AMI)
    #
    # See: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html
    #
    # Certain AMI virtualization types are incompatible with certain instance types. HVM
    # AMI types are recommended since they are compatible with most instance types.
    #
    # Compatibility matrix: https://aws.amazon.com/amazon-linux-ami/instance-type-matrix/
    #
    # Red Hat Enterprise Linux AMI IDs: http://aws.amazon.com/partners/redhat/
    #
    # We support RHEL and CentOS 6.5, 6.7, 6.8, 7.1, 7.2, and 7.3.
    # RHEL 7.2 is supported only for Cloudera Manager and CDH 5.7 and higher.
    # RHEL 6.8 and 7.3 are supported only for Cloudera Manager and CDH 5.10 and higher.
    #
    # To use Amazon EC2 D2 instances, you must run a minimum version of RHEL 6.7 or CentOS 6.7

    image: ami-7cbc6e13 #example of a CentOS image - ideally you have a pre-baked image with CM, CDH and SDC on it
    tags {
      owner: ${?USER}
      Owner: ${?USER}
    }

    # Turning off mountAllUnmountedDisks is necessary for CDSW to work, as CDSW handles
    # this step on its own
    #normalizationConfig {
        #mountAllUnmountedDisks: false
    #}

    bootstrapScripts: [ """#!/bin/sh

    # Install jdk 1.8 required by Spark2
    yum remove -y *openjdk*
    rpm -ivh "https://archive.cloudera.com/director/redhat/7/x86_64/director/2.6.0/RPMS/x86_64/oracle-j2sdk1.8-1.8.0+update121-1.x86_64.rpm"

    echo 'Installing demo data for StreamSets demo from public GitHub...'
    sudo yum install git -y
    cd /tmp
    git clone https://github.com/guidooswald/streamsets.git
    sudo chmod 777 streamsets/ -R

    exit 0
    """ ]
}

#
# A list of instance types to use for groups of nodes or management services. Instances
# specified here inherit from the common-instance-properties properties specified above.
#
instances {
    m4x: ${common-instance-properties} {
        type: m4.xlarge
    }

    m42x: ${common-instance-properties} {
        type: m4.2xlarge
    }

    m44x: ${common-instance-properties} {
        type: m4.4xlarge
    }
    m4xW : ${common-instance-properties} {
      type: m4.xlarge

      ebsVolumeCount : 3
      ebsVolumeType: st1 # specify either st1, sc1 or gp2 volume type
      ebsVolumeSizeGiB: 500
    }

    c34x : ${common-instance-properties} {
      type: c3.4xlarge
    }

    c38x : ${common-instance-properties} {
      type: c3.8xlarge
    }

    c44x : ${common-instance-properties} {
      type: c4.4xlarge
    }

    i2x : ${common-instance-properties} {
      type: i2.xlarge
    }

    i22x : ${common-instance-properties} {
      type: i2.2xlarge
    }

    d2x : ${common-instance-properties} {
      type: d2.xlarge
    }

    d22x : ${common-instance-properties} {
      type: d2.2xlarge
    }

    d24x : ${common-instance-properties} {
      type: d2.4xlarge
    }

    t2l : ${common-instance-properties} {   # only suitable as a gateway
      type: t2.large
    }
}

databaseServers {
   directormysql {
       type: mysql
       host: REPLACE-ME # with IP address of database server
       port: 3306
       user: REPLACE-ME
       password: "REPLACE-ME"
   }
}

cloudera-manager {

    instance: ${instances.m4x} {
      placementGroup: REPLACE-ME
      instanceNamePrefix: REPLACE-ME
        tags {
            application: "Cloudera Manager 5"
        }
    }

    enableEnterpriseTrial: true

    # jdk 1.8 is already installed in instance bootstrap
    javaInstallationStrategy: NONE

    repository: "https://archive.cloudera.com/cm5/redhat/7/x86_64/cm/5.14/"
    repositoryKeyUrl: "https://archive.cloudera.com/cm5/redhat/7/x86_64/cm/RPM-GPG-KEY-cloudera"

    configs {
        CLOUDERA_MANAGER {
            enable_api_debug: true
            custom_banner_html: "Managed by Cloudera Director"
        }

        # Custom service descriptors for Streamsets, CDSW and Spark2
      }

      databaseTemplates {
          CLOUDERA_MANAGER {
              name: cmtemplate
              databaseServerName: directormysql # Must correspond to an external database server named above
              databaseNamePrefix: scm
              usernamePrefix: cmadmin
          }

          ACTIVITYMONITOR {
 		 	 name: amtemplate
              databaseServerName: directormysql # Must correspond to an external database server named above
              databaseNamePrefix: am
              usernamePrefix: amadmin
 		}

          REPORTSMANAGER {
 		 	 name: rmtemplate
              databaseServerName: directormysql # Must correspond to an external database server named above
              databaseNamePrefix: rm
              usernamePrefix: rmadmin
 		 }

          NAVIGATOR {
 		 	 name: navtemplate
              databaseServerName: directormysql # Must correspond to an external database server named above
              databaseNamePrefix: nav
              usernamePrefix: nvadmin
 		 }

          # Added in Cloudera Manager 5.2+
          NAVIGATORMETASERVER {
 		 	 name: nmtemplate
              databaseServerName: directormysql # Must correspond to an external database server named above
              databaseNamePrefix: nm
              usernamePrefix: nmadmin
 		 }
      }


      csds: [
          "https://archive.cloudera.com/cdsw/1/csd/CLOUDERA_DATA_SCIENCE_WORKBENCH-1.3.0.jar",
          "https://archive.cloudera.com/spark2/csd/SPARK2_ON_YARN-2.3.0.cloudera2.jar"
            "https://archives.streamsets.com/datacollector/3.2.0.0/csd/STREAMSETS-3.2.0.0.jar"
      ]

}


externalAccounts {

    # External account that uses AWS Access Key Authentication. This type of authentication
    # will require adding the AWS_S3 service.
    AWSAccount1 {
        type: AWS_ACCESS_KEY_AUTH
        configs {
            aws_access_key: "REPLACE-ME"
            aws_secret_key: "REPLACE-ME"

            #
            # S3 Guard (added in CM/CDH 5.11) can be enabled to guarantee a consistent view of data stored
            # in Amazon S3 by storing additional metadata in a table residing in an Amazon DynamoDB instances.
            # See https://www.cloudera.com/documentation/enterprise/latest/topics/cm_s3guard.html for more
            # details and additional S3 Guard configuration properties.
            #

            # s3guard_enable: false
            # s3guard_region: REPLACE-ME
            # s3guard_table_name: s3guard-metadata
            # s3guard_table_auto_create: false
        }
    }

    # External account that uses IAM Role Authentication. This type of authentication doesn't
    # require adding the AWS_S3 service unless it has S3 guard enabled.
    AWSAccount2 {
        type: AWS_IAM_ROLES_AUTH
    }
}

#
# Cluster description
#

cluster {

    # List the products and their versions that need to be installed.
    # These products must have a corresponding parcel in the parcelRepositories
    # configured above. The specified version will be used to find a suitable
    # parcel. Specifying a version that points to more than one parcel among
    # those available will result in a configuration error. Specify more granular
    # versions to avoid conflicts.

    products {
      CDH: 5 # includes Impala and Spark
#      CDSW: 1.3
      KAFKA: 3
      SPARK2: 2
      STREAMSETS_DATACOLLECTOR: 3
    }

    parcelRepositories: ["https://archive.cloudera.com/cdh5/parcels/5.14/",
                         "https://archive.cloudera.com/spark2/parcels/2.3.0.cloudera2/",
                         #"https://archive.cloudera.com/cdsw/1/parcels/1.3.0/",
                         "https://archive.cloudera.com/kafka/parcels/3.0/",
                         "https://archives.streamsets.com/datacollector/3.2.0.0/parcel/"
                         ]

    #services: [HDFS, YARN, ZOOKEEPER, HBASE, HIVE, IMPALA, SPARK_ON_YARN, SPARK2_ON_YARN, HUE]

    services: [
                HDFS,
                YARN,
                ZOOKEEPER,
                HBASE,
                HIVE,
                HUE,
                OOZIE,
                SPARK_ON_YARN,
                KAFKA,
                SOLR,
                FLUME,
                IMPALA,
                SQOOP,
                #ACCUMULO16,
                #KS_INDEXER,
                #SENTRY,    # Sentry requires Kerberos to be enabled
                SPARK2_ON_YARN,
                KUDU,
                # AWS_S3     # Requires Sentry and Kerberos (on default configuraitons)
                STREAMSETS
              ]


  configs {
    	HDFS {
          core_site_safety_valve: "<property><name>fs.s3a.access.key</name><value>REPLACE-ME</value></property><property><name>fs.s3a.secret.key</name><value>REPLACE-ME</value></property>"
        }
#		HUE {
#		  hue_safety_valve: "[aws] [[aws_accounts]] [[[default]]] access_key_id=REPLACE-ME secret_access_key=REPLACE-ME allow_environment_credentials=false region=eu-central-1"
#		}

	}

     databaseTemplates: {
         HIVE {
             name: hivetemplate
             databaseServerName: directormysql # Must correspond to an external database server named above
             databaseNamePrefix: hivemetastore
             usernamePrefix: hive
         },

        HUE {
            name: huet
            databaseServerName: directormysql # Must correspond to an external database server named above
            databaseNamePrefix: hue
            usernamePrefix: hueu
        },

        OOZIE {
            name: ooziet
            databaseServerName: directormysql # Must correspond to an external database server named above
            databaseNamePrefix: oozie
            usernamePrefix: oozieu
        },

		SENTRY {
             name: sentrytemplate
             databaseServerName: directormysql
             databaseNamePrefix: sentrydb
             usernamePrefix: sentry
         },
     }

     cli-masters {
       count: 1

       instance: ${instances.m4x} {
         placementGroup: REPLACE-ME
         instanceNamePrefix: REPLACE-ME
         tags {
           application: "cli Master"
           group: master
           owner: ${?USER}
           Owner: ${?USER}
         }
         useSpotInstances: true
         spotBidUSDPerHr: 0.35 # Can be set/overridden per instance group
       }

       roles {
         HDFS: [NAMENODE, SECONDARYNAMENODE]
         YARN: [RESOURCEMANAGER, JOBHISTORY]
         ZOOKEEPER: [SERVER]
         HIVE: [HIVESERVER2, HIVEMETASTORE]
         HBASE: [MASTER, HBASETHRIFTSERVER]
         HUE: [HUE_SERVER]
         OOZIE: [OOZIE_SERVER]
         IMPALA: [STATESTORE,CATALOGSERVER]
         SOLR: [SOLR_SERVER]
         SQOOP: [SQOOP_SERVER]
         KAFKA: [KAFKA_BROKER]
         SPARK_ON_YARN: [SPARK_YARN_HISTORY_SERVER,GATEWAY]
         SPARK2_ON_YARN: [SPARK2_YARN_HISTORY_SERVER,GATEWAY]
         KUDU: [KUDU_MASTER]
       }

 	  configs {
         KUDU {
             KUDU_MASTER {
                 # The master rarely performs IO. If fs_data_dirs is unset, it will
                 # use the same directory as fs_wal_dir
                 fs_wal_dir: "/data0/kudu/masterwal"
                 fs_data_dirs: "/data1/kudu/master"
             }
          }
       }
     }

     cli-workers {
       count: 0
       minCount: 0

       instance: ${instances.m4xW} {
         placementGroup: REPLACE-ME
         instanceNamePrefix: REPLACE-ME
         tags {
           application: "cli Worker"
           group: worker
           owner: ${?USER}
           Owner: ${?USER}
         }
       }

       roles {
         HDFS: [DATANODE]
         YARN: [NODEMANAGER]
         HBASE: [REGIONSERVER]
         HIVE: [GATEWAY]
         FLUME: [AGENT]
         IMPALA: [IMPALAD]
         KUDU: [KUDU_TSERVER]
         SPARK_ON_YARN: [GATEWAY]
         SPARK2_ON_YARN: [GATEWAY]
       }

       configs {
         KUDU {
           KUDU_TSERVER {
             # Set fs_wal_dir to an SSD drive (if exists) for better performance.
             # Set fs_data_dirs to a comma-separated string containing all remaining
             # disk drives, solid state or otherwise.
             # If there are multiple drives in the machine, it's best to ensure that
             # the WAL directory is not located on the same disk as a tserver data
             # directory.
             fs_wal_dir: "/data0/kudu/tabletwal"
             fs_data_dirs: "/data1/kudu/tablet"
           }
         }
       }
     }

     # Spot instance group configuration
     # See: http://www.cloudera.com/documentation/director/latest/topics/director_aws_using_spot_instances.html
     cli-workers-spot {
        count: 3
        minCount: 3

        instance: ${instances.m42xW} {
         placementGroup: REPLACE-ME
         instanceNamePrefix: REPLACE-ME
         tags {
           application: "cli WorkerSpot"
           group: worker-spot
           owner: ${?USER}
           Owner: ${?USER}
         }
          useSpotInstances: true
          spotBidUSDPerHr: 0.35 # Can be set/overridden per instance group
        }

 	  roles {
      HDFS: [DATANODE]
      YARN: [NODEMANAGER]
      HBASE: [REGIONSERVER]
      HIVE: [GATEWAY]
      FLUME: [AGENT]
      IMPALA: [IMPALAD]
      KUDU: [KUDU_TSERVER]
      SPARK_ON_YARN: [GATEWAY]
      SPARK2_ON_YARN: [GATEWAY]
       }


       configs {
        KUDU {
           KUDU_TSERVER {
             fs_wal_dir: "/data0/kudu/tabletwal"
             fs_data_dirs: "/data1/kudu/tablet"
           }
         }
       }


      }

      gateways {
        count: 1

        instance: ${instances.m4x} {
          placementGroup: REPLACE-ME
          instanceNamePrefix: REPLACE-ME
          tags {
            group: gateway
            application: "cli GatewaySpot"
            owner: ${?USER}
            Owner: ${?USER}
          }
          useSpotInstances: true
          spotBidUSDPerHr: 0.35 # Can be set/overridden per instance group
        }

        roles {
          YARN: [GATEWAY]
          HDFS: [GATEWAY]
          HBASE: [GATEWAY]
          HIVE: [GATEWAY]
          SPARK_ON_YARN: [GATEWAY]
          SPARK2_ON_YARN: [GATEWAY]
          SOLR: [GATEWAY]
          #KAFKA: [GATEWAY]
          #ACCUMULO16: [GATEWAY]
          STREAMSETS: [DATACOLLECTOR]
        }

        #
        # Optional custom role configurations
        # Configuration keys containing special characters (e.g., '.', ':') must be enclosed in double quotes.
        #
        # Configuration properties for CDH roles and services are documented at
        # http://www.cloudera.com/documentation/enterprise/properties/5-13-x/topics/cm_props_cdh5130.html
        #

        # Configuration keys containing periods must be enclosed in double quotes.
        # configs {
        #   HIVE {
        #     GATEWAY {
        #       hive_metastore_timeout: 3000
        #       client_config_root_dir: /etc/hive
        #     }
        #   }
        # }
      }

    postCreateScripts: ["""#!/bin/sh

# This is an embedded post creation script script that runs as root and can be used to
# customize the cluster after it has been created.

# Use exit code 0 to indicate success
# Use exit code 91 indicate an unretryable failure
# Cloudera Director will automatically retry script execution for all other exit codes

echo 'Installing demo data for StreamSets demo from public GitHub...'
sudo yum install git -y
cd /tmp
git clone https://github.com/guidooswald/streamsets.git
sudo chmod 777 streamsets/ -R

echo 'Hello World!'
exit 0
    """,
    """#!/bin/sh

# Additionally, multiple post creation scripts can be supplied.  They will run in the
# order they are listed here.

echo 'Hello again!'
exit 0
    """]
}
